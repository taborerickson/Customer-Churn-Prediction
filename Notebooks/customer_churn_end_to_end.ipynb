{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac968a5",
   "metadata": {},
   "source": [
    "# Customer Churn Predictions \n",
    "(End-to-end customer churn prediction project) \n",
    "### Using Telco Customer Churn dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd2d77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure dpendencies are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import os \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from pathlib import Path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1e5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random_state for reproducibility \n",
    "random_state = 42 \n",
    "np.random.seed(random_state) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3123a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Path -->  Data/telco_churn_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Defining folder paths \n",
    "# Current directory --> Notebooks/ \n",
    "#data_path = \"../Data/telco_churn_data.csv\" \n",
    "#visuals_path = \"../Visuals\"\n",
    "#model_path = \"../Models\"   \n",
    "\n",
    "data_path = Path('../Data/telco_churn_data.csv') \n",
    "visuals_path = Path('../Visuals') \n",
    "models_path = Path('../Models') \n",
    "\n",
    "visuals_path.mkdir(parents=True, exist_ok=True) \n",
    "models_path.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "print(\"Data Path --> \", data_path) \n",
    "\n",
    "# Function to save data file(s) to Data/ folder \n",
    "def save_data(data: pd.DataFrame, file_name: str): \n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    file_name = os.path.join(save_path, f\"{file_name}.csv\") \n",
    "    data.to_csv(file_path, index=False) \n",
    "    print(f\"Saved -> {file_path}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting settings \n",
    "sns.set_style('whitegrid') \n",
    "plt.rcParams['figure.figsize'] = (10,6) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "\n",
    "# file path check \n",
    "if not data_path.exists(): \n",
    "    raise FileNotFoundError(f\"Expected data at {data_path}.\") \n",
    "\n",
    "telco_data = pd.read_csv(data_path) \n",
    "telco_data.head() \n",
    "print(\"\\nData Info: \")\n",
    "print(telco_data.info())  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = telco_data.copy() \n",
    "\n",
    "# Data checks \n",
    "print(\"\\nMissing values: \") \n",
    "print(data.isna().sum()) \n",
    "\n",
    "# Checking if there are duplicate customerID values \n",
    "print(\"\\nAll unique customerID --> \", data['customerID'].nunique() == len(data)) \n",
    "\n",
    "# Making sure TotalCharges is numeric \n",
    "if data['TotalCharges'].dtype != 'int': \n",
    "    data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce') \n",
    "    print(\"\\nTotalCharges NA count (After numeric conversion): \", data['TotalCharges'].isna().sum())\n",
    "\n",
    "# Checking if any rows have tenure == 0 & TotalCharges == NaN \n",
    "# Possible for new customers \n",
    "new_cust = (data['tenure'] == 0) & (data['TotalCharges'].isna()) \n",
    "print(\"\\nRows with tenure == 0 & TotalCharges == NaN : \", new_cust.sum()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data to Data/ folder \n",
    "save_data(data, \"cleaned_raw_data\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1787313f",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) \n",
    "Looking at group churn rates, population comparisons, visualziations, and interpretations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding baseline churn rate (Total churn rate) \n",
    "print(\"Baseline churn:\") \n",
    "print(data['Churn'].value_counts(normalize=True)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution \n",
    "ax = sns.countplot(x='Churn', data=data) \n",
    "ax.set_title(\"Churn Distribution (count)\") \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68411fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savings churn distribution figure to Visuals/ folder \n",
    "ax = sns.countplot(x='Churn', data=data) \n",
    "ax.set_title(\"Churn Distribution (count)\") \n",
    "plt.savefig(visuals_path / 'churn_distribution.png', dpi=150, bbox_inches='tight') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating helper function to calculate cross-tabulations and group churn rates \n",
    "def group_churn(data, group_column, target='Churn'): \n",
    "    cross_tab = pd.crosstab(data[group_column], data[target], normalize='index') \n",
    "    cross_tab = cross_tab.rename(columns={'No': 'churn_no_pct', 'Yes': 'churn_yes_pct'}) \n",
    "    # Population comparison \n",
    "    population_share = data[group_column].value_counts(normalize=True).rename('population_share') \n",
    "    result = cross_tab.join(population_share) \n",
    "    result['group_churn'] = result['churn_yes_pct'] \n",
    "    result['population_churn_share'] = result['population_share'] * result['churn_yes_pct'] \n",
    "    return result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475e7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c814cf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dc80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083a22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f80687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data \n",
    "data_path = \"../Data/telco_churn_data.csv\"\n",
    "telco_data = pd.read_csv(data_path)  \n",
    "print(telco_data.info()) \n",
    "print(\"\\n\", telco_data.head())\n",
    "\n",
    "\n",
    "# Saving cleaned data to data folder \n",
    "def save_data(data: pd.DataFrame, file_name: str): \n",
    "    os.makedirs(save_path, exist_ok=True) \n",
    "    file_path = os.path.join(save_path, f\"{file_name}.csv\") \n",
    "    data.to_csv(file_path, index=False) \n",
    "    print(f\"Saved -> {file_path}\") \n",
    "\n",
    "#save_path = \"../Data/\" \n",
    "#save_data(cleaned_data, \"cleaned_churn_data\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf3f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db820c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Libraries \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV  \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    average_precision_score, \n",
    "    roc_curve, \n",
    "    precision_recall_curve, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.pipeline import Pipeline as ImbPipeline \n",
    "\n",
    "import joblib \n",
    "\n",
    "# Heavy Libraries \n",
    "try: \n",
    "    import xgboost as xgb \n",
    "except Exception: \n",
    "    xgb = None \n",
    "\n",
    "try: \n",
    "    import shap \n",
    "except Exception: \n",
    "    shap = None \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735c098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd58a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d8e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc562c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
